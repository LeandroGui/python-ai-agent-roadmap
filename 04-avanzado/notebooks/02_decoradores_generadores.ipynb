{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMajhx-7v_qL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cortex Nivel 4: Decoradores y Generadores\n",
        "\n",
        "Estas dos herramientas permiten cambiar el comportamiento de funciones y manejar flujos de datos infinitos.\n",
        "\n",
        "## 1. Decoradores (`@decorador`)\n",
        "Un decorador es una funci贸n que \"envuelve\" a otra funci贸n para agregarle funcionalidad extra sin tocar su c贸digo original.\n",
        "* **Uso en Agentes:**\n",
        "    * `@retry`: Reintentar autom谩ticamente si la API de OpenAI falla.\n",
        "    * `@time_it`: Medir cu谩nto tarda una herramienta en ejecutarse.\n",
        "    * `@tool`: Registrar una funci贸n autom谩ticamente en el sistema del agente.\n",
        "\n",
        "## 2. Generadores (`yield`)\n",
        "A diferencia de una funci贸n normal que devuelve todo de golpe (`return`), un generador entrega los datos uno por uno (`yield`) y se \"pausa\" hasta que le pidas el siguiente.\n",
        "* **Uso en IA:** Streaming. Cuando ChatGPT te escribe palabra por palabra, est谩 usando un generador. Permite procesar Datasets que no caben en la memoria RAM."
      ],
      "metadata": {
        "id": "bTsziKJlwR4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "# --- 1. DECORADORES ---\n",
        "\n",
        "def measure_time(func):\n",
        "    \"\"\"Decorador que mide el tiempo de ejecuci贸n.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f\"憋 [{func.__name__}] tard贸 {end - start:.4f} segs\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@measure_time\n",
        "def complex_calculation():\n",
        "    \"\"\"Simula una tarea pesada.\"\"\"\n",
        "    time.sleep(2) # Simular espera\n",
        "    return \"C谩lculo terminado\"\n",
        "\n",
        "print(\"--- Probando Decorador ---\")\n",
        "complex_calculation()\n",
        "\n",
        "\n",
        "# --- 2. GENERADORES ---\n",
        "\n",
        "def llm_stream_simulation():\n",
        "    \"\"\"Simula el streaming de tokens de un LLM.\"\"\"\n",
        "    response = \"La inteligencia artificial es el futuro.\"\n",
        "    for word in response.split():\n",
        "        yield word # Entrega una palabra y PAUSA\n",
        "        time.sleep(0.5) # Simula latencia de red\n",
        "\n",
        "print(\"\\n--- Probando Generador (Streaming) ---\")\n",
        "# El bucle 'for' pide el siguiente valor autom谩ticamente\n",
        "for token in llm_stream_simulation():\n",
        "    print(f\"Token recibido: {token}\")"
      ],
      "metadata": {
        "id": "dU_lF0DvwQ5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e8d9ae-eb0d-428f-c4af-235f38ac434e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Probando Decorador ---\n",
            "憋 [complex_calculation] tard贸 2.0001 segs\n",
            "\n",
            "--- Probando Generador (Streaming) ---\n",
            "Token recibido: La\n",
            "Token recibido: inteligencia\n",
            "Token recibido: artificial\n",
            "Token recibido: es\n",
            "Token recibido: el\n",
            "Token recibido: futuro.\n"
          ]
        }
      ]
    }
  ]
}